% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dispersion_analysis_helper_functions.R
\name{find_max_disp}
\alias{find_max_disp}
\title{Find the optimum distribution (dispersion maximum) for a vector of subfrequencies and part sizes}
\usage{
find_max_disp(subfreq, partsize, freq_adjust_method = "pervasive_even")
}
\arguments{
\item{subfreq}{A numeric vector of subfrequencies, i.e. the number of occurrences of the item in each corpus part}

\item{partsize}{A numeric vector with the size of the corpus parts}

\item{freq_adjust_method}{Character string indicating which method to used for devising a 'maximally dispersed' distribution of the item, which is necessary for frequency adjustment. See details below. Possible values are \code{'pervasive'} (default) and \code{'pervasive_even'}}
}
\value{
An integer vector of the same length as the number of corpus parts.
}
\description{
This function returns the (hypothetical) distribution of subfrequencies that represents the highest possible level of dispersion for the item across the corpus parts. It requires a vector of subfrequencies and a vector of corpus part sizes. This distribution is required for the min-max transformation proposed by Gries (2024: 196-208) to obtain frequency-adjusted dispersion scores.
}
\details{
This function creates a hypothetical distribution of the total number of occurrences of the item (i.e. the sum of the subfrequencies) across the corpus parts. To obtain the highest possible level of dispersion, two methods are available. The choice between these methods is particularly relevant if corpus parts differ considerably in size.

The first method prioritizes pervasiveness (\code{pervasive}), which means that it creates a distribution with the widest possible spread of the item across corpus parts. It first arranges the corpus parts by size, in decreasing order. Then one occurrence of the item is assigned to each part, starting with the largest part, and continuing to(wards) the smallest part. The allocation of occurrences to parts therefore largely disregards the size of the parts. If the number of occurrences of the item exceeds the number of corpus parts, we start afresh with the largest corpus part. If the smallest corpus part(s) cannot hold any further occurrences (i.e. if they are "full"), the allocation returns to the largest corpus part.

The second method, which is EXPERIMENTAL, strives for a balance between pervasiveness and evenness (\code{pervasive_even}). This means that the allocation of occurrences also takes into account the size of the corpus parts. During the allocation process, an occurrence may therefore not be assigned to the next-smaller corpus part if a larger part makes an extra occurrence of the item more likely due to its length. In principle, weights can be assigned to pervasiveness and evenness to represent their relative importance. At the moment, no weighting scheme has been devised, which is why this method is currently EXPERIMENTAL.
}
\examples{
\dontrun{
# not run
find_max_disp(
  subfreq = c(0,0,1,2,5), 
  partsize = c(100, 100, 100, 500, 1000),
  freq_adjust_method = "pervasive")
}

}
\author{
Lukas Soenning
}
